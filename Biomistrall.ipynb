{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bejB42RBwpS3",
        "outputId": "53a9a962-5639-4836-9445-fef345f98c10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requirements.txt\n",
        "streamlit\n",
        "torch\n",
        "numpy\n",
        "faiss-cpu\n",
        "transformers\n",
        "huggingface-hub\n",
        "langchain\n",
        "langchain-community\n",
        "langchain-huggingface\n",
        "pyngrok\n",
        "llama-cpp-python\n",
        "PyPDF\n",
        "tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grXodpQ0tvd7",
        "outputId": "3f0cb466-d86b-4db0-c9d9-7bc752627a18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n",
            "Collecting streamlit (from -r requirements.txt (line 1))\n",
            "  Downloading streamlit-1.43.2-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
            "Collecting faiss-cpu (from -r requirements.txt (line 4))\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (4.48.3)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.28.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.3.20)\n",
            "Collecting langchain-community (from -r requirements.txt (line 8))\n",
            "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-huggingface (from -r requirements.txt (line 9))\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (7.2.3)\n",
            "Collecting llama-cpp-python (from -r requirements.txt (line 11))\n",
            "  Downloading llama_cpp_python-0.3.8.tar.gz (67.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyPDF (from -r requirements.txt (line 12))\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (4.67.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 1)) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 1)) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 1)) (8.1.8)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 1)) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 1)) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 1)) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 1)) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 1)) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 1)) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit->-r requirements.txt (line 1))\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 1)) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit->-r requirements.txt (line 1))\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 1)) (6.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 5)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 5)) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 5)) (0.5.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain->-r requirements.txt (line 7)) (0.3.44)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain->-r requirements.txt (line 7)) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain->-r requirements.txt (line 7)) (0.3.13)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain->-r requirements.txt (line 7)) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain->-r requirements.txt (line 7)) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community->-r requirements.txt (line 8)) (3.11.13)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community->-r requirements.txt (line 8))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community->-r requirements.txt (line 8))\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community->-r requirements.txt (line 8))\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface->-r requirements.txt (line 9)) (3.4.1)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python->-r requirements.txt (line 11))\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8)) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 8)) (1.18.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 1)) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 1)) (1.30.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 8))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 8))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 1)) (4.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain->-r requirements.txt (line 7)) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 7)) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 7)) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 7)) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 7)) (0.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit->-r requirements.txt (line 1)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit->-r requirements.txt (line 1)) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 7)) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->-r requirements.txt (line 8))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 1)) (2025.1.31)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface->-r requirements.txt (line 9)) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface->-r requirements.txt (line 9)) (1.14.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 7)) (3.1.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 1)) (5.0.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 7)) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 7)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 7)) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain->-r requirements.txt (line 7)) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 1)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 1)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 1)) (0.23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit->-r requirements.txt (line 1)) (1.17.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 8))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface->-r requirements.txt (line 9)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface->-r requirements.txt (line 9)) (3.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 7)) (1.3.1)\n",
            "Downloading streamlit-1.43.2-py2.py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.8-cp311-cp311-linux_x86_64.whl size=5959638 sha256=c3e3fe4e069f2cd54ade5bb26f34b0e5ef1d99359413026bfaf4b56d4be9ca48\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/03/66/eb3810eafd55d921b2be32896d1f44313996982360663aa80b\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: watchdog, python-dotenv, PyPDF, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, marshmallow, httpx-sse, faiss-cpu, diskcache, typing-inspect, pydeck, nvidia-cusparse-cu12, nvidia-cudnn-cu12, llama-cpp-python, pydantic-settings, nvidia-cusolver-cu12, dataclasses-json, streamlit, langchain-huggingface, langchain-community\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed PyPDF-5.4.0 dataclasses-json-0.6.7 diskcache-5.6.3 faiss-cpu-1.10.0 httpx-sse-0.4.0 langchain-community-0.3.19 langchain-huggingface-0.1.2 llama-cpp-python-0.3.8 marshmallow-3.26.1 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydantic-settings-2.8.1 pydeck-0.9.1 python-dotenv-1.0.1 streamlit-1.43.2 typing-inspect-0.9.0 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pyngrok\n",
        "!pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2I1egxfYSIh"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "\n",
        "output.clear()\n",
        "!echo \"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>\" > ~/.huggingface\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFdW7FD1ZEQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d34387-fea9-4163-f2de-945f904acc23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmU633H7EQBf",
        "outputId": "9f6b16eb-5841-43d1-9a0d-6b50f871fb26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import logging\n",
        "import torch\n",
        "from langchain.schema import Document\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from huggingface_hub import hf_hub_download, login\n",
        "import faiss\n",
        "import pickle\n",
        "import time\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = \"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\"\n",
        "\n",
        "login(token=os.environ[\"HUGGINGFACE_HUB_TOKEN\"])\n",
        "\n",
        "os.makedirs('logs', exist_ok=True)\n",
        "\n",
        "logging.basicConfig(\n",
        "    filename='logs/app.log',\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s:%(levelname)s:%(message)s'\n",
        ")\n",
        "\n",
        "valores_referencia = {\n",
        "    \"Hemácias (milhões/mm³)\": {\"H\": (4.5, 6.5), \"M\": (4, 5)},\n",
        "    \"Hemoglobina (g/dL)\": {\"H\": (13, 18), \"M\": (12.0, 15.5)},\n",
        "    \"Hematócrito (%)\": {\"H\": (40, 54), \"M\": (36, 45)},\n",
        "    \"VCM (fL)\": {\"H\": (80, 98), \"M\": (80, 98)},\n",
        "    \"HCM (pg)\": {\"H\": (27, 32), \"M\": (27, 32)},\n",
        "    \"CHCM (g/dL)\": {\"H\": (32, 36), \"M\": (32, 36)},\n",
        "    \"RDW (%)\": {\"H\": (11, 15), \"M\": (11, 15)},\n",
        "    \"Leucócitos (/mm³)\": {\"H\": (4000, 10000), \"M\": (4000, 10000)},\n",
        "    \"Neutrófilos Relativos (%)\": {\"H\": (40, 75), \"M\": (40, 75)},\n",
        "    \"Neutrófilos Absolutos (/mm³)\": {\"H\": (1600, 7500), \"M\": (1600, 7500)},\n",
        "    \"Eosinófilos Relativos (%)\": {\"H\": (1, 5), \"M\": (1, 5)},\n",
        "    \"Eosinófilos Absolutos (/mm³)\": {\"H\": (40, 500), \"M\": (40, 500)},\n",
        "    \"Basófilos Relativos (%)\": {\"H\": (0, 2), \"M\": (0, 2)},\n",
        "    \"Basófilos Absolutos (/mm³)\": {\"H\": (0, 200), \"M\": (0, 200)},\n",
        "    \"Monócitos Relativos (%)\": {\"H\": (2, 10), \"M\": (2, 10)},\n",
        "    \"Monócitos Absolutos (/mm³)\": {\"H\": (80, 1000), \"M\": (80, 1000)},\n",
        "    \"Linfócitos Relativos (%)\": {\"H\": (25, 45), \"M\": (25, 45)},\n",
        "    \"Linfócitos Absolutos (/mm³)\": {\"H\": (1000, 4500), \"M\": (1000, 4500)},\n",
        "    \"Plaquetas (/mm³)\": {\"H\": (150000, 450000), \"M\": (150000, 450000)},\n",
        "}\n",
        "\n",
        "fallback_respostas = {\n",
        "    \"Hemácias (milhões/mm³)\": {\n",
        "         \"baixo\": \"Pode indicar anemia, que pode ser causada por deficiência de ferro, vitamina B12 ou ácido fólico, hemorragia aguda ou crônica, doenças crônicas ou problemas na medula óssea. (Fonte: SBPC/ML)\",\n",
        "         \"alto\": \"Sugere policitemia, que pode ser primária (como na policitemia vera) ou secundária a condições como hipóxia crônica (ex.: DPOC) ou desidratação. (Fonte: SBPC/ML)\"\n",
        "    },\n",
        "    \"Hemoglobina (g/dL)\": {\n",
        "         \"baixo\": \"Indica anemia, com sintomas como cansaço, fraqueza, tontura e palidez. Causas incluem deficiências nutricionais, perda sanguínea ou doenças hematológicas. (Fonte: Ministério da Saúde do Brasil e SBPC/ML)\",\n",
        "         \"alto\": \"Sugere policitemia ou desidratação. Em casos de policitemia, pode aumentar o risco de trombose. (Fonte: Ministério da Saúde do Brasil e SBPC/ML)\"\n",
        "    },\n",
        "    \"Hematócrito (%)\": {\n",
        "         \"baixo\": \"Reflete anemia, com possíveis causas semelhantes às da hemoglobina baixa. (Fonte: SBPC/ML)\",\n",
        "         \"alto\": \"Pode ser causado por desidratação ou policitemia, aumentando a viscosidade sanguínea e o risco de complicações cardiovasculares. (Fonte: SBPC/ML)\"\n",
        "    },\n",
        "    \"VCM (fL)\": {\n",
        "         \"baixo\": \"Indica microcitose, comum em anemias ferroprivas. (Fonte: Manual de Hematologia Clínica - SBPC/ML)\",\n",
        "         \"alto\": \"Sugere macrocitose, associada a deficiências de vitamina B12 ou ácido fólico. (Fonte: Manual de Hematologia Clínica - SBPC/ML)\",\n",
        "         \"normal\": \"Não exclui anemia, mas ajuda a classificá-la. (Fonte: Manual de Hematologia Clínica - SBPC/ML)\"\n",
        "    },\n",
        "    \"HCM (pg)\": {\n",
        "         \"baixo\": \"Sugere hipocromia, frequentemente associada à anemia ferropriva. (Fonte: SBPC/ML)\",\n",
        "         \"alto\": \"Pode ocorrer em macrocitoses, como nas deficiências de vitamina B12 ou ácido fólico. (Fonte: SBPC/ML)\"\n",
        "    },\n",
        "    \"CHCM (g/dL)\": {\n",
        "         \"baixo\": \"Indica hipocromia, geralmente associada à anemia ferropriva. (Fonte: SBPC/ML)\",\n",
        "         \"alto\": \"Raramente alterado, mas pode ocorrer em condições como esferocitose hereditária. (Fonte: SBPC/ML)\"\n",
        "    },\n",
        "    \"RDW (%)\": {\n",
        "         \"baixo\": \"Pouco relevante clinicamente. (Fonte: SBPC/ML)\",\n",
        "         \"alto\": \"Sugere anisocitose, comum em anemias ferroprivas, megaloblásticas ou após tratamento de deficiências nutricionais. (Fonte: SBPC/ML)\"\n",
        "    },\n",
        "    \"Leucócitos (/mm³)\": {\n",
        "         \"baixo\": \"Indica leucopenia, que pode ser causada por infecções virais, quimioterapia, doenças autoimunes ou problemas na medula óssea. (Fonte: SBPC/ML)\",\n",
        "         \"alto\": \"Sugere leucocitose, comum em infecções bacterianas, inflamações, estresse ou leucemias. (Fonte: SBPC/ML)\"\n",
        "    },\n",
        "    \"Neutrófilos Relativos (%)\": {\n",
        "         \"baixo\": \"Aumenta o risco de infecções, podendo ser causado por infecções virais, uso de medicamentos ou doenças hematológicas. (Fonte: SBPC/ML)\",\n",
        "         \"alto\": \"Sugere infecções bacterianas, inflamações, estresse físico ou uso de corticoides. (Fonte: SBPC/ML)\"\n",
        "    },\n",
        "    \"Neutrófilos Absolutos (/mm³)\": {\n",
        "         \"baixo\": \"Aumenta o risco de infecções, podendo ser causado por infecções virais, uso de medicamentos ou doenças hematológicas. (Fonte: SBPC/ML)\",\n",
        "         \"alto\": \"Sugere infecções bacterianas, inflamações, estresse físico ou uso de corticoides. (Fonte: SBPC/ML)\"\n",
        "    },\n",
        "    \"Eosinófilos Relativos (%)\": {\n",
        "         \"baixo\": \"Raramente clinicamente relevante. (Fonte: SBPC/ML)\",\n",
        "         \"alto\": \"Associado a alergias, parasitoses, doenças autoimunes ou neoplasias hematológicas. (Fonte: SBPC/ML)\"\n",
        "    },\n",
        "    \"Eosinófilos Absolutos (/mm³)\": {\n",
        "         \"baixo\": \"Raramente clinicamente relevante. (Fonte: SBPC/ML)\",\n",
        "         \"alto\": \"Associado a alergias, parasitoses, doenças autoimunes ou neoplasias hematológicas. (Fonte: SBPC/ML)\"\n",
        "    },\n",
        "    \"Basófilos Relativos (%)\": {\n",
        "         \"baixo\": \"Geralmente sem significado clínico. (Fonte: SBPC/ML)\",\n",
        "         \"alto\": \"Pode ocorrer em doenças mieloproliferativas, como a leucemia mieloide crônica. (Fonte: SBPC/ML)\"\n",
        "    },\n",
        "    \"Basófilos Absolutos (/mm³)\": {\n",
        "         \"baixo\": \"Geralmente sem significado clínico. (Fonte: SBPC/ML)\",\n",
        "         \"alto\": \"Pode ocorrer em doenças mieloproliferativas, como a leucemia mieloide crônica. (Fonte: SBPC/ML)\"\n",
        "    },\n",
        "    \"Monócitos Relativos (%)\": {\n",
        "         \"baixo\": \"Raramente clinicamente relevante. (Fonte: SBPC/ML)\",\n",
        "         \"alto\": \"Sugere infecções crônicas, doenças inflamatórias ou neoplasias hematológicas. (Fonte: SBPC/ML)\"\n",
        "    },\n",
        "    \"Monócitos Absolutos (/mm³)\": {\n",
        "         \"baixo\": \"Raramente clinicamente relevante. (Fonte: SBPC/ML)\",\n",
        "         \"alto\": \"Sugere infecções crônicas, doenças inflamatórias ou neoplasias hematológicas. (Fonte: SBPC/ML)\"\n",
        "    },\n",
        "    \"Linfócitos Relativos (%)\": {\n",
        "         \"baixo\": \"Pode ocorrer em infecções virais graves, imunodeficiências ou uso de medicamentos imunossupressores. (Fonte: SBPC/ML)\",\n",
        "         \"alto\": \"Comum em infecções virais ou leucemias linfocíticas. (Fonte: SBPC/ML)\"\n",
        "    },\n",
        "    \"Linfócitos Absolutos (/mm³)\": {\n",
        "         \"baixo\": \"Pode ocorrer em infecções virais graves, imunodeficiências ou uso de medicamentos imunossupressores. (Fonte: SBPC/ML)\",\n",
        "         \"alto\": \"Comum em infecções virais ou leucemias linfocíticas. (Fonte: SBPC/ML)\"\n",
        "    },\n",
        "    \"Plaquetas (/mm³)\": {\n",
        "         \"baixo\": \"Aumenta o risco de sangramento, podendo ser causado por doenças autoimunes, infecções virais, medicação ou doenças hematológicas. (Fonte: SBPC/ML)\",\n",
        "         \"alto\": \"Pode ser reativa ou primária, aumentando o risco de trombose. (Fonte: SBPC/ML)\"\n",
        "    }\n",
        "}\n",
        "\n",
        "class CustomEmbeddings:\n",
        "    def __init__(self, model_name):\n",
        "        logging.info(f\"Carregando modelo e tokenizer: {model_name}\")\n",
        "        #os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "        self.model = AutoModel.from_pretrained(model_name)\n",
        "        self.device = torch.device(\"cpu\")\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def embed_texts(self, texts):\n",
        "        if not texts or not all(isinstance(text, str) and text.strip() for text in texts):\n",
        "            raise ValueError(\"Os textos para embeddings devem ser uma lista de strings não vazias.\")\n",
        "\n",
        "        logging.info(\"Calculando embeddings...\")\n",
        "        inputs = self.tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(self.device)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "\n",
        "        if not isinstance(embeddings, np.ndarray) or embeddings.ndim != 2:\n",
        "            raise ValueError(\"Os embeddings gerados devem ser uma matriz 2D (n_texts x n_features).\")\n",
        "\n",
        "        return embeddings\n",
        "\n",
        "    def embed_documents(self, documents):\n",
        "        logging.info(\"Convertendo documentos para texto antes de calcular embeddings.\")\n",
        "        if not documents or not all(isinstance(doc, Document) for doc in documents):\n",
        "            raise ValueError(\"Todos os documentos devem ser instâncias de `Document`.\")\n",
        "        texts = [doc.page_content.strip() for doc in documents if doc.page_content.strip()]\n",
        "        return self.embed_texts(texts)\n",
        "\n",
        "def preprocessar_texto(texto):\n",
        "    import re\n",
        "    texto = re.sub(r\"Página\\s*\\d+\\s*de\\s*\\d+\", \"\", texto)\n",
        "    texto = re.sub(r\"(.+)\\n\\1\", \"\", texto)\n",
        "    texto = re.sub(r\"\\s+\", \" \", texto).strip()\n",
        "    return texto\n",
        "\n",
        "@st.cache_data\n",
        "def load_documents():\n",
        "    try:\n",
        "        index_path = '/content/drive/MyDrive/IC/faiss_index_flat.bin'\n",
        "        texts_path = '/content/drive/MyDrive/IC/texts.pkl'\n",
        "\n",
        "        if os.path.exists(index_path) and os.path.exists(texts_path):\n",
        "            index = faiss.read_index(index_path)\n",
        "            with open(texts_path, 'rb') as f:\n",
        "                texts = pickle.load(f)\n",
        "            logging.info(\"Índice FAISS e textos carregados do cache.\")\n",
        "            return index, texts\n",
        "\n",
        "        loader = PyPDFDirectoryLoader('/content/drive/MyDrive/IC/Data/')\n",
        "        raw_docs = loader.load()\n",
        "        docs = [Document(page_content=preprocessar_texto(doc.page_content)) for doc in raw_docs if doc.page_content.strip()]\n",
        "        logging.info(f\"Documentos carregados: {len(docs)}\")\n",
        "\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=800,\n",
        "            chunk_overlap=64,\n",
        "            length_function=lambda x: len(x.split())\n",
        "        )\n",
        "        chunks = text_splitter.split_documents(docs)\n",
        "        texts = [chunk.page_content.strip() for chunk in chunks]\n",
        "        logging.info(f\"Chunks gerados: {len(texts)}\")\n",
        "\n",
        "        embeddings, _ = load_embeddings_and_llm()\n",
        "        text_embeddings = embeddings.embed_texts(tuple(texts)).astype(\"float32\")\n",
        "\n",
        "        index = faiss.IndexFlatL2(text_embeddings.shape[1])\n",
        "        index.add(text_embeddings)\n",
        "        logging.info(\"Índice FAISS criado com sucesso.\")\n",
        "\n",
        "        faiss.write_index(index, index_path)\n",
        "        with open(texts_path, 'wb') as f:\n",
        "            pickle.dump(texts, f)\n",
        "\n",
        "        return index, texts\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro ao carregar documentos: {e}\")\n",
        "        raise\n",
        "\n",
        "@st.cache_resource\n",
        "def load_embeddings_and_llm():\n",
        "    logging.info(\"Carregando embeddings e LLM...\")\n",
        "    try:\n",
        "        embeddings = CustomEmbeddings(\"pucpr/biobertpt-all\")\n",
        "        logging.info(\"Embeddings carregados com sucesso.\")\n",
        "\n",
        "        llm_model_path = \"/content/drive/MyDrive/IC/BioMistral-7B.Q4_K_M.gguf\"\n",
        "        if not os.path.exists(llm_model_path):\n",
        "            raise FileNotFoundError(f\"Modelo LLM não encontrado: {llm_model_path}\")\n",
        "\n",
        "        llm = LlamaCpp(\n",
        "            model_path=llm_model_path,\n",
        "            temperature=0.2,\n",
        "            max_tokens=800,\n",
        "            n_ctx=8192,\n",
        "            top_p=0.95,\n",
        "            n_batch=512,\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        logging.info(\"LLM carregado com sucesso.\")\n",
        "        return embeddings, llm\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro ao carregar embeddings ou LLM: {e}\")\n",
        "        st.error(f\"Erro ao carregar embeddings ou LLM: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "def identificar_anomalias(inputs, genero):\n",
        "    anormalidades = {}\n",
        "    for exame, valor in inputs.items():\n",
        "        if valor is not None and exame in valores_referencia:\n",
        "            try:\n",
        "                ref_min, ref_max = valores_referencia[exame][genero]\n",
        "                if valor < ref_min:\n",
        "                    diferenca = ref_min - valor\n",
        "                    gravidade = classificar_gravidade(diferenca, ref_min)\n",
        "                    anormalidades[exame] = (valor, \"baixo\", gravidade)\n",
        "                elif valor > ref_max:\n",
        "                    diferenca = valor - ref_max\n",
        "                    gravidade = classificar_gravidade(diferenca, ref_max)\n",
        "                    anormalidades[exame] = (valor, \"alto\", gravidade)\n",
        "                else:\n",
        "                    anormalidades[exame] = (valor, \"normal\", None)\n",
        "            except KeyError:\n",
        "                logging.error(f\"Erro ao obter valores de referência para {exame}\")\n",
        "                continue\n",
        "    return anormalidades\n",
        "\n",
        "def classificar_gravidade(diferenca, referencia):\n",
        "    percentual = (diferenca / referencia) * 100\n",
        "    if percentual <= 10:\n",
        "        return \"leve\"\n",
        "    elif percentual <= 20:\n",
        "        return \"moderada\"\n",
        "    else:\n",
        "        return \"severa\"\n",
        "\n",
        "def contar_tokens(texto):\n",
        "    return len(texto.split())\n",
        "\n",
        "def filtrar_chunks_relevantes(chunks, query_embedding_np, embeddings, threshold=0.5):\n",
        "    relevant_chunks = []\n",
        "    for chunk in chunks:\n",
        "        chunk_embedding = embeddings.embed_texts([chunk])\n",
        "        similarity = cosine_similarity(query_embedding_np, chunk_embedding)[0][0]\n",
        "        if similarity > threshold:\n",
        "            relevant_chunks.append(chunk)\n",
        "    return relevant_chunks\n",
        "\n",
        "def buscar_explicacao_pdf(exame, condicao, retriever, embeddings, llm):\n",
        "    query = (\n",
        "        f\"Explicação clínica sobre {exame} estar {condicao} em exames de sangue. \"\n",
        "        f\"Possíveis causas, significado clínico, diagnóstico diferencial, \"\n",
        "        f\"e recomendações para {exame} {condicao}.\"\n",
        "    )\n",
        "    logging.info(f\"Buscando explicação para: {query}\")\n",
        "\n",
        "    index, texts = retriever\n",
        "    query_embedding = embeddings.embed_texts([query])\n",
        "    query_embedding_np = np.array(query_embedding).astype(\"float32\")\n",
        "\n",
        "    D, I = index.search(query_embedding_np, k=2)\n",
        "    similar_chunks = [texts[idx] for idx in I[0]]\n",
        "    relevant_chunks = filtrar_chunks_relevantes(similar_chunks, query_embedding_np, embeddings, threshold=0.5)\n",
        "    logging.info(f\"Chunks relevantes encontrados: {len(relevant_chunks)}\")\n",
        "\n",
        "    def get_fallback():\n",
        "        return fallback_respostas.get(exame, {}).get(\n",
        "            condicao, \"Explicação clínica não disponível no momento.\"\n",
        "        )\n",
        "\n",
        "    if not relevant_chunks:\n",
        "        logging.warning(\"Nenhum chunk relevante encontrado. Usando fallback.\")\n",
        "        return get_fallback()\n",
        "\n",
        "    contexto = \"\\n\".join(relevant_chunks)\n",
        "    logging.debug(f\"Contexto para o LLM: {contexto[:500]}...\")\n",
        "\n",
        "    prompt = (\n",
        "        f\"Você é um hematologist explicando para um paciente. Com base no contexto clínico abaixo, \"\n",
        "        f\"explique de forma clara e acessível para um paciente.\\n\\n\"\n",
        "        f\"**Contexto clínico relevante:**\\n{contexto}\\n\\n\"\n",
        "        f\"**Pergunta 1:** Explique de forma concisa o que significa {exame} {condicao} no contexto clínico.\\n\"\n",
        "        f\"**Pergunta 2:** Quais são as causas mais comuns dessa condição? Liste até 3 possíveis causas.\\n\"\n",
        "        f\"**Pergunta 3:** Quais são as ações recomendadas para acompanhamento e tratamento dessa condição? \"\n",
        "        f\"Liste até 2 recomendações práticas.\\n\\n\"\n",
        "        f\"**Instruções (Português):**\\n\"\n",
        "        f\"- Use uma linguagem simples e evite termos técnicos que o paciente não entenderia.\\n\"\n",
        "        f\"- Caso não tenha informações suficientes para uma resposta precisa, responda com 'Informação não disponível'.\\n\\n\"\n",
        "    )\n",
        "\n",
        "    logging.debug(f\"Prompt enviado ao LLM: {prompt}\")\n",
        "\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        resposta = llm.invoke(prompt)\n",
        "        elapsed_time = time.time() - start_time\n",
        "        logging.info(f\"Tempo gasto na geração do LLM: {elapsed_time:.2f} segundos\")\n",
        "        logging.info(f\"Resposta do LLM: {resposta}\")\n",
        "\n",
        "        if not resposta or \"não disponível\" in resposta.lower() or len(resposta.strip()) < 58:\n",
        "            logging.warning(\"Resposta do LLM inválida ou insuficiente. Usando fallback.\")\n",
        "            return get_fallback()\n",
        "\n",
        "        return resposta\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro ao gerar explicação com o LLM: {e}\")\n",
        "        return get_fallback()\n",
        "\n",
        "def gerar_relatorio(anormalidades, retriever, llm, genero, embeddings):\n",
        "    if not anormalidades:\n",
        "        return \"Nenhuma anomalia detectada nos exames fornecidos.\"\n",
        "\n",
        "    relatorio = \"# Relatório de Análise de Exames de Sangue\\n\\n\"\n",
        "    relatorio += \"## Anomalias Detectadas\\n\\n\"\n",
        "\n",
        "    exames_normais = []\n",
        "\n",
        "    for exame, detalhes in anormalidades.items():\n",
        "        valor = detalhes[0]\n",
        "        condicao = detalhes[1]\n",
        "        gravidade = detalhes[2]\n",
        "        ref_min, ref_max = valores_referencia.get(exame, {}).get(genero, (None, None))\n",
        "\n",
        "        if condicao == \"normal\":\n",
        "            exames_normais.append(exame)\n",
        "            continue\n",
        "\n",
        "        relatorio += f\"### {exame}\\n\\n\"\n",
        "        relatorio += \"| **Parâmetro**         | **Valor** |\\n\"\n",
        "        relatorio += \"|------------------------|-----------|\\n\"\n",
        "        relatorio += f\"| Valor Encontrado       | {valor}    |\\n\"\n",
        "        relatorio += f\"| Condição               | {condicao.capitalize()} |\\n\"\n",
        "        relatorio += f\"| Gravidade              | {gravidade.capitalize()} |\\n\"\n",
        "        if ref_min is not None and ref_max is not None:\n",
        "            relatorio += f\"| Valores de Referência  | {ref_min} - {ref_max} |\\n\"\n",
        "        relatorio += \"\\n\"\n",
        "\n",
        "        explicacao = buscar_explicacao_pdf(exame, condicao, retriever, embeddings, llm)\n",
        "        relatorio += f\"**Possível Significado Clínico:** {explicacao}\\n\\n\"\n",
        "\n",
        "    if exames_normais:\n",
        "        relatorio += \"## Exames Dentro da Faixa Normal\\n\\n\"\n",
        "        relatorio += \"Os seguintes exames estão dentro dos valores de referência:\\n\"\n",
        "        for exame in exames_normais:\n",
        "            relatorio += f\"- {exame}\\n\"\n",
        "        relatorio += \"\\n\"\n",
        "\n",
        "    relatorio += \"## Recomendações\\n\"\n",
        "    relatorio += \"- As interpretações são geradas por um sistema treinado com dados médicos, e não substitui consultas médicas profissionais.\\n\"\n",
        "    relatorio += \"- Consulte um hematologista para avaliação detalhada.\\n\"\n",
        "    relatorio += \"- Realize exames adicionais (ferritina, vitamina B12, ácido fólico, etc.).\\n\"\n",
        "    relatorio += \"- Monitore os parâmetros regularmente.\\n\"\n",
        "\n",
        "    return relatorio\n",
        "\n",
        "def main():\n",
        "    embeddings, llm = load_embeddings_and_llm()\n",
        "    index, texts = load_documents()\n",
        "\n",
        "    st.title(\"Análise de Exames de Sangue\")\n",
        "    genero = st.selectbox(\"Selecione o Gênero\", [\"H\", \"M\"])\n",
        "\n",
        "    inputs = {\n",
        "        \"Hemácias (milhões/mm³)\": st.number_input(\"Hemácias (milhões/mm³)\"),\n",
        "        \"Hemoglobina (g/dL)\": st.number_input(\"Hemoglobina (g/dL)\"),\n",
        "        \"Hematócrito (%)\": st.number_input(\"Hematócrito (%)\"),\n",
        "        \"VCM (fL)\": st.number_input(\"VCM (fL)\"),\n",
        "        \"HCM (pg)\": st.number_input(\"HCM (pg)\"),\n",
        "        \"CHCM (g/dL)\": st.number_input(\"CHCM (g/dL)\"),\n",
        "        \"RDW (%)\": st.number_input(\"RDW (%)\"),\n",
        "        \"Leucócitos (/mm³)\": st.number_input(\"Leucócitos (/mm³)\"),\n",
        "        \"Neutrófilos Relativos (%)\": st.number_input(\"Neutrófilos Relativos (%)\"),\n",
        "        \"Neutrófilos Absolutos (/mm³)\": st.number_input(\"Neutrófilos Absolutos (/mm³)\"),\n",
        "        \"Eosinófilos Relativos (%)\": st.number_input(\"Eosinófilos Relativos (%)\"),\n",
        "        \"Eosinófilos Absolutos (/mm³)\": st.number_input(\"Eosinófilos Absolutos (/mm³)\"),\n",
        "        \"Basófilos Relativos (%)\": st.number_input(\"Basófilos Relativos (%)\"),\n",
        "        \"Basófilos Absolutos (/mm³)\": st.number_input(\"Basófilos Absolutos (/mm³)\"),\n",
        "        \"Monócitos Relativos (%)\": st.number_input(\"Monócitos Relativos (%)\"),\n",
        "        \"Monócitos Absolutos (/mm³)\": st.number_input(\"Monócitos Absolutos (/mm³)\"),\n",
        "        \"Linfócitos Relativos (%)\": st.number_input(\"Linfócitos Relativos (%)\"),\n",
        "        \"Linfócitos Absolutos (/mm³)\": st.number_input(\"Linfócitos Absolutos (/mm³)\"),\n",
        "        \"Plaquetas (/mm³)\": st.number_input(\"Plaquetas (/mm³)\"),\n",
        "    }\n",
        "\n",
        "    if st.button(\"Gerar Relatório\"):\n",
        "        with st.spinner(\"Analisando...\"):\n",
        "            st.write(\"Identificando anomalias...\")\n",
        "            anormalidades = identificar_anomalias(inputs, genero)\n",
        "\n",
        "            if anormalidades:\n",
        "                st.write(\"Gerando relatório...\")\n",
        "                relatorio = gerar_relatorio(anormalidades, (index, texts), llm, genero, embeddings)\n",
        "                with st.expander(\"Relatório Completo\"):\n",
        "                    st.markdown(relatorio)\n",
        "            else:\n",
        "                st.write(\"Nenhuma anomalia detectada nos exames fornecidos.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9DZM2170LMb"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcap2LjpONNO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk98yEM5Zkp9",
        "outputId": "0d25b7f6-05c5-4316-ee89-35105029be0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL pública do app: NgrokTunnel: \"https://e5e1-34-148-189-201.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "import time\n",
        "import sys\n",
        "\n",
        "ngrok.set_auth_token(\"2radu8dntChVEaAHvz1QjSPe8RD_5mfK8GazAUZ393X11y11a\")\n",
        "!streamlit run app.py &>/dev/null &\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"URL pública do app: {public_url}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}